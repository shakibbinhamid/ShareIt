\chapter{User Participation}
\label{chap:user}

In this chapter, I discuss why and how I have interviewed the potential users of the app, as well as my experiences in doing so.

\section{Reason}

Even though I had a vision of what the app could be, the specific user stories must be structured and prioritised \textit{only} to the \textit{end users'} needs. So, the first round of interviews were run to empathise with my users' pain points. For example - I asked the users - \textit{Which of these features are more important to you and in what order and why such order?} (Appendix \ref{sec:interview1}), and the response dictated where I needed to concentrate. This idea stems from the simple fact that - "those affected by a design should have a say in the design process" \cite{Bjogvinsson:2012}. In fact, I turned the responses into user stories in backlog (See Chapter \ref{chap:proj-org}) and their pain points allowed me to prioritise them.\\

I also felt it necessary to define UX goals (e.g. evaluate navigation and white space use etc.) and run interactive interviews with the \textit{end users}. It is because users typically interact with mobile apps very differently to their desktop counterparts (e.g. average user spends about an hour a day on apps, whereas each session only lasts around a minute! \cite{Bohmer:2011}). So, even established assumptions about interaction often falls behind \cite{Sullivan:2013}. Responses to questions like - \textit{How do you know if someone responded to the ’x’ you posted earlier?} (Appendix \ref{sec:interview2}) pointed out some obvious faults in the app during UX evaluation when they could not complete the task in expected time or take the expected navigation route. I turned the issues into estimated work items (Appendix \ref{appendix:ux}) and fixed them in the following sprint.\\

\section{Methodology}

For each user participation period, I defined a goal first e.g. gain a better understanding of sharing economy between students in UoS and produce wireframes for RE period. Then a data collection method (e.g. interview, questionnaire, focus group, observations etc.) was chosen. I chose individual structured interviews with consented audio recording, physical notes and observation for qualitative data. I also asked them to speak aloud what they were thinking or doing. This method was chosen because video recording is time consuming and difficult to get \textit{right}, questionnaires often remove empathy and focus groups proved difficult to organise \cite{Arhippainen:2003}. I also believed qualitative data will provide more information than quantitative for my purposes.\\

Then I made interview scripts (with generally open ended approach to the questions), estimated time taken, applied for ethical approval with consent form and data protection guarantee. The notes taken were cross checked with the recorded audio for each individual afterwards. Data was kept secure on my personal laptop. It was then turned into user stories and prioritised based on observation. I also used the information to confirm prior assumptions.

\section{Experiences in RE}

I found two very distinct groups of interviewees in my first interview period - one group will express themselves a lot more than the others, rarely there was an \textit{ideal} persona. So, it soon proved difficult to keep track of the structured questions as the answers would often overlap or that there was barely any data from certain interviewees. As a result, interviews almost always ran overtime than what was estimated.\\

The planned interactive wireframing session, where users draw out how they believed their most desired features would be implemented, was very successful and productive. Every interviewee engaged easily and provided me with crucial ideas on how to structure UI elements and implement navigation. Similar experiences with card sorting technique, where they prioritised the important featured, which helped me prioritise user stories even in later stages.\\

I had also found it extremely helpful to have a very early prototype running on the mobile device \cite{Kangas:2005} that I used to develop the app, even during RE session. It gave a better perspective about wireframing to both the participants and I, and removed the usual gulf between the two parties \cite{Vermeeren:2010}.

\section{Experiences in UX Evaluation}

I had corrected my approach to the interview questions based on previous the experiences and made them slightly more specific and task based so as to keep the interviewees focused. Resultantly, the sessions ran almost exactly as long as they were estimated to run.\\

Very simple bugs, some of which I was aware of but never fixed because they were not prioritised (e.g. reverse chronological ordering of products etc.), distracted the participants from main tasks. Although they could have been fixed in between different sessions, I did not do so as it would jeopardise the study. In future, I will fix all the simple and obvious bugs before I run evaluation sessions.\\

The results from the sessions were very satisfactory. In general, the participants found the interface to be \textit{intuitive}, \textit{fun} and \textit{easy} to navigate. They also found the information layout to be \textit{clean} and animations to add \textit{life} to the app.\\

There were 10 easily fixable (1-2 hours) and 4 much harder to fix (more than 10 hours) issues found (see Appendix \ref{appendix:ux}). Most of these (9/10 of the former, 2/4 of the latter) were addressed in the sprint that followed soon after. I can truly appreciate the importance of user evaluation at this point and would recommend doing so at least after every two iterations in any future work.